package org.apache.spark.listeners

import com.fasterxml.jackson.databind.ObjectMapper
import com.fasterxml.jackson.module.scala.DefaultScalaModule
import org.apache.spark.scheduler.{SparkListenerBlockManagerAdded, SparkListenerEnvironmentUpdate, SparkListenerEvent, SparkListenerStageSubmitted}
import org.apache.spark.streaming.scheduler.{ReceiverInfo, StreamingListenerReceiverStarted, StreamingListenerStreamingStarted}
import org.apache.spark.util.JsonProtocol
import org.json4s.jackson.JsonMethods.parse

object SparkTestEvents {

  private val testTimeStamp = 1422981759407L
  val iso8601TestTime = "2015-02-03T16:42:39.407Z"
  private val sparkListenerBlockManagerAdded = "{\"Event\":\"SparkListenerBlockManagerAdded\",\"Block Manager ID\":{\"Executor ID\":\"<driver>\",\"Host\":\"localhost\",\"Port\":57967},\"Maximum Memory\":278302556,\"Timestamp\":" + testTimeStamp + "}"
  val mapper: ObjectMapper = new ObjectMapper().registerModule(DefaultScalaModule)
  val sparkListenerBlockManagerAddedEvent: SparkListenerBlockManagerAdded = getSparkListenerEvent[SparkListenerBlockManagerAdded](sparkListenerBlockManagerAdded)
  private val sparkListenerStageSubmittedWithSubmissionTimeEmpty = "{\"Event\":\"SparkListenerStageSubmitted\",\"Stage Info\":{\"Stage ID\":0,\"Stage Attempt ID\":0,\"Stage Name\":\"count at <console>:15\",\"Number of Tasks\":8,\"RDD Info\":[{\"RDD ID\":0,\"Name\":\"0\",\"Storage Level\":{\"Use Disk\":false,\"Use Memory\":true,\"Use Tachyon\":false,\"Deserialized\":true,\"Replication\":1},\"Number of Partitions\":8,\"Number of Cached Partitions\":0,\"Memory Size\":0,\"Tachyon Size\":0,\"Disk Size\":0}],\"Details\":\"org.apache.spark.rdd.RDD.count(RDD.scala:910)\\n$line9.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:15)\\n$line9.$read$$iwC$$iwC$$iwC.<init>(<console>:20)\\n$line9.$read$$iwC$$iwC.<init>(<console>:22)\\n$line9.$read$$iwC.<init>(<console>:24)\\n$line9.$read.<init>(<console>:26)\\n$line9.$read$.<init>(<console>:30)\\n$line9.$read$.<clinit>(<console>)\\n$line9.$eval$.<init>(<console>:7)\\n$line9.$eval$.<clinit>(<console>)\\n$line9.$eval.$print(<console>)\\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\njava.lang.reflect.Method.invoke(Method.java:606)\\norg.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)\\norg.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)\\norg.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)\\norg.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)\\norg.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)\",\"Accumulables\":[]}}"
  val sparkListenerStageSubmittedWithSubmissonTimeEmptyEvent: SparkListenerStageSubmitted = getSparkListenerEvent[SparkListenerStageSubmitted](sparkListenerStageSubmittedWithSubmissionTimeEmpty)
  private val sparkListenerStageSubmitted = "{\"Event\":\"SparkListenerStageSubmitted\",\"Stage Info\":{\"Stage ID\":1,\"Stage Attempt ID\":0,\"Submission Time\":1422981759407,\"Stage Name\":\"map at <console>:14\",\"Number of Tasks\":8,\"RDD Info\":[{\"RDD ID\":1,\"Name\":\"1\",\"Storage Level\":{\"Use Disk\":false,\"Use Memory\":false,\"Use Tachyon\":false,\"Deserialized\":false,\"Replication\":1},\"Number of Partitions\":8,\"Number of Cached Partitions\":0,\"Memory Size\":0,\"Tachyon Size\":0,\"Disk Size\":0},{\"RDD ID\":0,\"Name\":\"0\",\"Storage Level\":{\"Use Disk\":false,\"Use Memory\":true,\"Use Tachyon\":false,\"Deserialized\":true,\"Replication\":1},\"Number of Partitions\":8,\"Number of Cached Partitions\":0,\"Memory Size\":0,\"Tachyon Size\":0,\"Disk Size\":0}],\"Details\":\"\",\"Accumulables\":[]}}"
  val sparkListenerStageSubmittedEvent: SparkListenerStageSubmitted = getSparkListenerEvent[SparkListenerStageSubmitted](sparkListenerStageSubmitted)
  private val sparkListenerEnvironmentUpdate = "{\"Event\":\"SparkListenerEnvironmentUpdate\",\"JVM Information\":{\"Java Home\":\"/Library/Java/JavaVirtualMachines/jdk1.7.0_67.jdk/Contents/Home/jre\",\"Java Version\":\"1.7.0_67 (Oracle Corporation)\",\"Scala Version\":\"version 2.10.4\"},\"Spark Properties\":{\"spark.driver.host\":\"192.168.1.103\",\"spark.eventLog.enabled\":\"true\",\"spark.driver.port\":\"57965\",\"spark.repl.class.uri\":\"http://192.168.1.103:57964\",\"spark.jars\":\"\",\"spark.app.name\":\"Spark shell\",\"spark.scheduler.mode\":\"FIFO\",\"spark.executor.id\":\"driver\",\"spark.master\":\"local[*]\",\"spark.fileserver.uri\":\"http://192.168.1.103:57966\",\"spark.tachyonStore.folderName\":\"spark-fd6c823a-8a18-4113-8306-1fa7bb623a7f\",\"spark.app.id\":\"local-1422981759269\"},\"System Properties\":{\"java.io.tmpdir\":\"/var/folders/36/m29jw1z95qv4ywb1c4n0rz000000gp/T/\",\"line.separator\":\"\\n\",\"path.separator\":\":\",\"sun.management.compiler\":\"HotSpot 64-Bit Tiered Compilers\",\"SPARK_SUBMIT\":\"true\",\"sun.cpu.endian\":\"little\",\"java.specification.version\":\"1.7\",\"java.vm.specification.name\":\"Java Virtual Machine Specification\",\"java.vendor\":\"Oracle Corporation\",\"java.vm.specification.version\":\"1.7\",\"user.home\":\"/Users/irashid\",\"file.encoding.pkg\":\"sun.io\",\"sun.nio.ch.bugLevel\":\"\",\"ftp.nonProxyHosts\":\"local|*.local|169.254/16|*.169.254/16\",\"sun.arch.data.model\":\"64\",\"sun.boot.library.path\":\"/Library/Java/JavaVirtualMachines/jdk1.7.0_67.jdk/Contents/Home/jre/lib\",\"user.dir\":\"/Users/irashid/spark-examples/releases/spark-1.2.0-bin-hadoop2.4\",\"java.library.path\":\"/Users/irashid/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.\",\"sun.cpu.isalist\":\"\",\"os.arch\":\"x86_64\",\"java.vm.version\":\"24.65-b04\",\"java.endorsed.dirs\":\"/Library/Java/JavaVirtualMachines/jdk1.7.0_67.jdk/Contents/Home/jre/lib/endorsed\",\"java.runtime.version\":\"1.7.0_67-b01\",\"java.vm.info\":\"mixed mode\",\"java.ext.dirs\":\"/Users/irashid/Library/Java/Extensions:/Library/Java/JavaVirtualMachines/jdk1.7.0_67.jdk/Contents/Home/jre/lib/ext:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java\",\"java.runtime.name\":\"Java(TM) SE Runtime Environment\",\"file.separator\":\"/\",\"java.class.version\":\"51.0\",\"java.specification.name\":\"Java Platform API Specification\",\"sun.boot.class.path\":\"/Library/Java/JavaVirtualMachines/jdk1.7.0_67.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.7.0_67.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.7.0_67.jdk/Contents/Home/jre/lib/sunrsasign.jar:/Library/Java/JavaVirtualMachines/jdk1.7.0_67.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.7.0_67.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.7.0_67.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.7.0_67.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.7.0_67.jdk/Contents/Home/jre/classes\",\"file.encoding\":\"UTF-8\",\"user.timezone\":\"America/Chicago\",\"java.specification.vendor\":\"Oracle Corporation\",\"sun.java.launcher\":\"SUN_STANDARD\",\"os.version\":\"10.9.5\",\"sun.os.patch.level\":\"unknown\",\"gopherProxySet\":\"false\",\"java.vm.specification.vendor\":\"Oracle Corporation\",\"user.country\":\"US\",\"sun.jnu.encoding\":\"UTF-8\",\"http.nonProxyHosts\":\"local|*.local|169.254/16|*.169.254/16\",\"user.language\":\"en\",\"socksNonProxyHosts\":\"local|*.local|169.254/16|*.169.254/16\",\"java.vendor.url\":\"http://java.oracle.com/\",\"java.awt.printerjob\":\"sun.lwawt.macosx.CPrinterJob\",\"java.awt.graphicsenv\":\"sun.awt.CGraphicsEnvironment\",\"awt.toolkit\":\"sun.lwawt.macosx.LWCToolkit\",\"os.name\":\"Mac OS X\",\"java.vm.vendor\":\"Oracle Corporation\",\"java.vendor.url.bug\":\"http://bugreport.sun.com/bugreport/\",\"user.name\":\"irashid\",\"java.vm.name\":\"Java HotSpot(TM) 64-Bit Server VM\",\"sun.java.command\":\"org.apache.spark.deploy.SparkSubmit --class org.apache.spark.repl.Main --conf spark.eventLog.enabled=true spark-shell\",\"java.home\":\"/Library/Java/JavaVirtualMachines/jdk1.7.0_67.jdk/Contents/Home/jre\",\"java.version\":\"1.7.0_67\",\"sun.io.unicode.encoding\":\"UnicodeBig\"},\"Classpath Entries\":{\"/Users/irashid/spark-examples/releases/spark-1.2.0-bin-hadoop2.4/lib/spark-assembly-1.2.0-hadoop2.4.0.jar\":\"System Classpath\",\"/Users/irashid/spark-examples/releases/spark-1.2.0-bin-hadoop2.4/lib/datanucleus-api-jdo-3.2.6.jar\":\"System Classpath\",\"/Users/irashid/spark-examples/releases/spark-1.2.0-bin-hadoop2.4/lib/datanucleus-rdbms-3.2.9.jar\":\"System Classpath\",\"/Users/irashid/spark-examples/releases/spark-1.2.0-bin-hadoop2.4/lib/datanucleus-core-3.2.10.jar\":\"System Classpath\",\"/Users/irashid/spark-examples/releases/spark-1.2.0-bin-hadoop2.4/conf\":\"System Classpath\"}}"
  val sparkListenerEnvironmentUpdateEvent: SparkListenerEnvironmentUpdate = getSparkListenerEvent[SparkListenerEnvironmentUpdate](sparkListenerEnvironmentUpdate)
  val streamingListenerStreamingStartedEvent = StreamingListenerStreamingStarted(testTimeStamp)
  val streamingListenerReceiverStartedEvent = StreamingListenerReceiverStarted(ReceiverInfo(
    streamId = 2,
    name = "test",
    active = true,
    location = "localhost",
    executorId = "1"
  ))

  def getSparkListenerEvent[T <: SparkListenerEvent](jsonString: String): T = {

    JsonProtocol.sparkEventFromJson(parse(jsonString)).asInstanceOf[T]

  }


}
